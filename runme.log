+ ./BitEpi.o -i sampleData/data.csv -o sampleData/out -t 2 -b1 0 -b2 0 -b3 0 -b4 0 -a1 0 -a2 0 -a3 0 -a4 0 -sort

=============Start=============




=========================================

 Given Arguments:

 input                sampleData/data.csv
 output               sampleData/out
 threads              2
 sort
 beta1                0.000000
 alpha1               0.000000
 beta2                0.000000
 alpha2               0.000000
 beta3                0.000000
 alpha3               0.000000
 beta4                0.000000
 alpha4               0.000000

=========================================


loading dataset sampleData/data.csv
Counting lines in sampleData/data.csv

There are       51 lines    in sampleData/data.csv
There are       50 SNPs     in sampleData/data.csv
There are     4000 samples  in sampleData/data.csv
There are     2000 Cases    in sampleData/data.csv
There are     2000 Controls in sampleData/data.csv

Purity of the whole dataset is 0.500000 (baseline for Beta)

Shift dataset by 2 bits compeleted
Shift dataset by 4 bits compeleted
Shift dataset by 6 bits compeleted
> 1-SNP exhaustive search
> Processing 2 jobs [0..1] in parallel

>>>>> Identify the index range of the outer-loop for each job such that each job tests the same number of combinations (approximately)
Total number of combinations to be tested:                                   50
Average number of combintions to be tested in each job:                      25


         Job ID          Start            End   Combinations (to be tested in this job)
              0              0              0             49
              1              1             49              1
<<<<<
Thread     0 processing Job     0 ... Thread     0 processed Job     0 in          0 seconds Thread     1 processing Job     1 ... Thread     1 processed Job     1 in          0 seconds > All jobs are compeleted in          0 seconds


> 2-SNP exhaustive search
> Processing 2 jobs [0..1] in parallel

>>>>> Identify the index range of the outer-loop for each job such that each job tests the same number of combinations (approximately)
Total number of combinations to be tested:                                 1225
Average number of combintions to be tested in each job:                     612


         Job ID          Start            End   Combinations (to be tested in this job)
              0              0             13            595
              1             14             48            630
<<<<<
Thread     0 processing Job     0 ... Thread     1 processing Job     1 ... Thread     0 processed Job     0 in          0 seconds Thread     1 processed Job     1 in          0 seconds > All jobs are compeleted in          0 seconds


> 3-SNP exhaustive search
> Processing 2 jobs [0..1] in parallel

>>>>> Identify the index range of the outer-loop for each job such that each job tests the same number of combinations (approximately)
Total number of combinations to be tested:                                19600
Average number of combintions to be tested in each job:                    9800


         Job ID          Start            End   Combinations (to be tested in this job)
              0              0              9           9720
              1             10             47           9880
<<<<<
Thread     0 processing Job     0 ... Thread     1 processing Job     1 ... Thread     0 processed Job     0 in          0 seconds Thread     1 processed Job     1 in          0 seconds > All jobs are compeleted in          0 seconds


> 4-SNP exhaustive search
> Processing 2 jobs [0..1] in parallel

>>>>> Identify the index range of the outer-loop for each job such that each job tests the same number of combinations (approximately)
Total number of combinations to be tested:                               230300
Average number of combintions to be tested in each job:                  115150


         Job ID          Start            End   Combinations (to be tested in this job)
              0              0              7         118370
              1              8             46         111930
<<<<<
Thread     0 processing Job     0 ...
Thread     1 processing Job     1 ...
Thread     1 processed Job     1 in          1 seconds
Thread     0 processed Job     0 in          1 seconds
> All jobs are compeleted in          1 seconds



***Merge output of multiple threads (stored in separate files). In Linux it uses command line operation (also echo commands in stdout). In Windows it only merge the best output file.


Merge Beta1 files...

>>> cat sampleData/out.Beta.1.*.csv | sort -g -r -k1,1 -t ',' | awk 'BEGIN{print("Alpha,SNP_A")}{print}' > sampleData/out.Beta.1.csv

>>> rm sampleData/out.Beta.1.*.csv

Merge Alpha1 files...

>>> cat sampleData/out.Alpha.1.*.csv | sort -g -r -k1,1 -t ',' | awk 'BEGIN{print("Alpha,SNP_A")}{print}' > sampleData/out.Alpha.1.csv

>>> rm sampleData/out.Alpha.1.*.csv

Merge Beta2 files...

>>> cat sampleData/out.Beta.2.*.csv | sort -g -r -k1,1 -t ',' | awk 'BEGIN{print("Alpha,SNP_A,SNP_B")}{print}' > sampleData/out.Beta.2.csv

>>> rm sampleData/out.Beta.2.*.csv

Merge Alpha2 files...

>>> cat sampleData/out.Alpha.2.*.csv | sort -g -r -k1,1 -t ',' | awk 'BEGIN{print("Alpha,SNP_A,SNP_B")}{print}' > sampleData/out.Alpha.2.csv

>>> rm sampleData/out.Alpha.2.*.csv

Merge Beta3 files...

>>> cat sampleData/out.Beta.3.*.csv | sort -g -r -k1,1 -t ',' | awk 'BEGIN{print("Alpha,SNP_A,SNP_B,SNP_C")}{print}' > sampleData/out.Beta.3.csv

>>> rm sampleData/out.Beta.3.*.csv

Merge Alpha3 files...

>>> cat sampleData/out.Alpha.3.*.csv | sort -g -r -k1,1 -t ',' | awk 'BEGIN{print("Alpha,SNP_A,SNP_B,SNP_C")}{print}' > sampleData/out.Alpha.3.csv

>>> rm sampleData/out.Alpha.3.*.csv

Merge Beta4 files...

>>> cat sampleData/out.Beta.4.*.csv | sort -g -r -k1,1 -t ',' | awk 'BEGIN{print("Alpha,SNP_A,SNP_B,SNP_C,SNP_D")}{print}' > sampleData/out.Beta.4.csv

>>> rm sampleData/out.Beta.4.*.csv

Merge Alpha4 files...

>>> cat sampleData/out.Alpha.4.*.csv | sort -g -r -k1,1 -t ',' | awk 'BEGIN{print("Alpha,SNP_A,SNP_B,SNP_C,SNP_D")}{print}' > sampleData/out.Alpha.4.csv

>>> rm sampleData/out.Alpha.4.*.csv

=============Finish=============


+ ./BitEpi.o -i sampleData/data.csv -o sampleData/out -t 2 -best

=============Start=============




=========================================

 Given Arguments:

 input                sampleData/data.csv
 output               sampleData/out
 threads              2
 best

=========================================


loading dataset sampleData/data.csv
Counting lines in sampleData/data.csv

There are       51 lines    in sampleData/data.csv
There are       50 SNPs     in sampleData/data.csv
There are     4000 samples  in sampleData/data.csv
There are     2000 Cases    in sampleData/data.csv
There are     2000 Controls in sampleData/data.csv

Purity of the whole dataset is 0.500000 (baseline for Beta)

Shift dataset by 2 bits compeleted
Shift dataset by 4 bits compeleted
Shift dataset by 6 bits compeleted
> 1-SNP exhaustive search
> Processing 2 jobs [0..1] in parallel

>>>>> Identify the index range of the outer-loop for each job such that each job tests the same number of combinations (approximately)
Total number of combinations to be tested:                                   50
Average number of combintions to be tested in each job:                      25


         Job ID          Start            End   Combinations (to be tested in this job)
              0              0              0             49
              1              1             49              1
<<<<<
Thread     0 processing Job     0 ... Thread     0 processed Job     0 in          0 seconds Thread     1 processing Job     1 ... Thread     1 processed Job     1 in          0 seconds > All jobs are compeleted in          0 seconds


> 2-SNP exhaustive search
> Processing 2 jobs [0..1] in parallel

>>>>> Identify the index range of the outer-loop for each job such that each job tests the same number of combinations (approximately)
Total number of combinations to be tested:                                 1225
Average number of combintions to be tested in each job:                     612


         Job ID          Start            End   Combinations (to be tested in this job)
              0              0             13            595
              1             14             48            630
<<<<<
Thread     0 processing Job     0 ... Thread     1 processing Job     1 ... Thread     0 processed Job     0 in          0 seconds Thread     1 processed Job     1 in          0 seconds > All jobs are compeleted in          0 seconds


> 3-SNP exhaustive search
> Processing 2 jobs [0..1] in parallel

>>>>> Identify the index range of the outer-loop for each job such that each job tests the same number of combinations (approximately)
Total number of combinations to be tested:                                19600
Average number of combintions to be tested in each job:                    9800


         Job ID          Start            End   Combinations (to be tested in this job)
              0              0              9           9720
              1             10             47           9880
<<<<<
Thread     0 processing Job     0 ... Thread     1 processing Job     1 ... Thread     0 processed Job     0 in          0 seconds Thread     1 processed Job     1 in          0 seconds > All jobs are compeleted in          0 seconds


> 4-SNP exhaustive search
> Processing 2 jobs [0..1] in parallel

>>>>> Identify the index range of the outer-loop for each job such that each job tests the same number of combinations (approximately)
Total number of combinations to be tested:                               230300
Average number of combintions to be tested in each job:                  115150


         Job ID          Start            End   Combinations (to be tested in this job)
              0              0              7         118370
              1              8             46         111930
<<<<<
Thread     0 processing Job     0 ...
Thread     1 processing Job     1 ...
Thread     1 processed Job     1 in          1 seconds
Thread     0 processed Job     0 in          1 seconds
> All jobs are compeleted in          1 seconds



***Merge output of multiple threads (stored in separate files). In Linux it uses command line operation (also echo commands in stdout). In Windows it only merge the best output file.


=============Finish=============


+ ./BitEpi.o -i sampleData/data.csv -o sampleData/out -t 2 -b4 0 -c -j 5 -f 0 -sort

=============Start=============




=========================================

 Given Arguments:

 input                sampleData/data.csv
 output               sampleData/out
 threads              2
 total jobs           5
 jobs on this machine 2
 first job index      0
 last  job index      1
 sort
 beta4                0.000000

=========================================


loading dataset sampleData/data.csv
Counting lines in sampleData/data.csv

There are       51 lines    in sampleData/data.csv
There are       50 SNPs     in sampleData/data.csv
There are     4000 samples  in sampleData/data.csv
There are     2000 Cases    in sampleData/data.csv
There are     2000 Controls in sampleData/data.csv

Purity of the whole dataset is 0.500000 (baseline for Beta)

Shift dataset by 2 bits compeleted
Shift dataset by 4 bits compeleted
Shift dataset by 6 bits compeleted
> 4-SNP exhaustive search
> Processing 2 jobs [0..1] in parallel

>>>>> Identify the index range of the outer-loop for each job such that each job tests the same number of combinations (approximately)
Total number of combinations to be tested:                               230300
Average number of combintions to be tested in each job:                   46060


         Job ID          Start            End   Combinations (to be tested in this job)
              0              0              2          51935
              1              3              5          42614
              2              6              9          44361
              3             10             15          45014
              4             16             46          46376
<<<<<
Thread     0 processing Job     0 ...
Thread     1 processing Job     1 ...
Thread     1 processed Job     1 in          0 seconds
Thread     0 processed Job     0 in          0 seconds
> All jobs are compeleted in          0 seconds



***Merge output of multiple threads (stored in separate files). In Linux it uses command line operation (also echo commands in stdout). In Windows it only merge the best output file.


Merge Beta4 files...

>>> cat sampleData/out.Beta.4.0.1.*.csv | sort -g -r -k1,1 -t ',' | awk 'BEGIN{print("Alpha,SNP_A,SNP_B,SNP_C,SNP_D")}{print}' > sampleData/out.Beta.4.0.1.csv

>>> rm sampleData/out.Beta.4.0.1.*.csv

=============Finish=============


+ set +x
>>>>>>> Output files
-rw-rw-r-- 1 arash arash     661 Oct 28 13:42 sampleData/out.Alpha.1.csv
-rw-rw-r-- 1 arash arash   20794 Oct 28 13:42 sampleData/out.Alpha.2.csv
-rw-rw-r-- 1 arash arash  410448 Oct 28 13:42 sampleData/out.Alpha.3.csv
-rw-rw-r-- 1 arash arash 5739106 Oct 28 13:42 sampleData/out.Alpha.4.csv
-rw-rw-r-- 1 arash arash    5210 Oct 28 13:42 sampleData/out.best.csv
-rw-rw-r-- 1 arash arash     661 Oct 28 13:42 sampleData/out.Beta.1.csv
-rw-rw-r-- 1 arash arash   20794 Oct 28 13:42 sampleData/out.Beta.2.csv
-rw-rw-r-- 1 arash arash  410448 Oct 28 13:42 sampleData/out.Beta.3.csv
-rw-rw-r-- 1 arash arash 2283626 Oct 28 13:42 sampleData/out.Beta.4.0.1.csv
-rw-rw-r-- 1 arash arash 8022732 Oct 28 13:42 sampleData/out.Beta.4.csv
<<<<<<<<<<<<<<<<<<<<
